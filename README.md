# üìû An√°lise de Churn em Telecomunica√ß√µes

![Ci√™ncia de Dados](https://img.shields.io/badge/-Ci√™ncia%20de%20Dados-blueviolet)
![Machine Learning](https://img.shields.io/badge/-Machine%20Learning-orange)
![Python](https://img.shields.io/badge/-Python-yellowgreen)

# Informa√ß√£o do projeto (Miss√£o e objetivo)

Este projeto tem como objetivo desenvolver modelos preditivos para identificar clientes da Telecom X com maior probabilidade de cancelar seus servi√ßos. Atrav√©s da an√°lise de dados, pr√©-processamento, modelagem e interpreta√ß√£o, buscamos fornecer insights acion√°veis para a implementa√ß√£o de estrat√©gias de reten√ß√£o eficazes.

### üéØ Miss√£o
Desenvolver modelos preditivos capazes de prever quais clientes t√™m maior chance de cancelar seus servi√ßos.

A empresa quer antecipar o problema da evas√£o, e cabe a voc√™ construir um pipeline robusto para essa etapa inicial de modelagem.

### üß† Objetivos do Desafio
Preparar os dados para a modelagem (tratamento, encoding, normaliza√ß√£o).

Realizar an√°lise de correla√ß√£o e sele√ß√£o de vari√°veis.

Treinar dois ou mais modelos de classifica√ß√£o.

Avaliar o desempenho dos modelos com m√©tricas.

Interpretar os resultados, incluindo a import√¢ncia das vari√°veis.

Criar uma conclus√£o estrat√©gica apontando os principais fatores que influenciam a evas√£o.
"""

# Metodologia Sum√°rio 
## Metodologia

Este projeto seguiu um pipeline estruturado de an√°lise e modelagem de dados para prever a evas√£o de clientes. As principais etapas inclu√≠ram:

1.  **Carregamento e An√°lise Inicial dos Dados:** Os dados foram carregados a partir do arquivo 'telecomX_dados_tratados.csv' em um DataFrame pandas. Foi realizada uma inspe√ß√£o inicial dos dados, incluindo a visualiza√ß√£o de amostras, estat√≠sticas descritivas (`describe()`), informa√ß√µes sobre tipos de dados e valores n√£o nulos (`info()`), e a contagem de valores nulos por coluna (`isnull().sum()`).

2.  **Explora√ß√£o de Dados (EDA):** A an√°lise explorat√≥ria focou em entender a distribui√ß√£o da vari√°vel alvo (`churn`) e a rela√ß√£o entre as demais vari√°veis e o churn.
    *   A distribui√ß√£o da vari√°vel alvo foi visualizada usando um countplot, e a propor√ß√£o de churn foi calculada.
    *   A distribui√ß√£o das vari√°veis num√©ricas foi examinada atrav√©s de histogramas.
    *   Boxplots foram utilizados para visualizar a rela√ß√£o entre as vari√°veis num√©ricas e o churn.
    *   Countplots foram gerados para explorar a rela√ß√£o entre as vari√°veis categ√≥ricas e o churn.
    *   Uma matriz de correla√ß√£o foi plotada para entender a rela√ß√£o entre as vari√°veis num√©ricas.

3.  **Pr√©-processamento e Tratamento dos Dados:** Nesta etapa, os dados foram preparados para a modelagem.
    *   A coluna 'customerid', considerada irrelevante para a modelagem, foi removida.
    *   Vari√°veis categ√≥ricas foram codificadas usando One-Hot Encoding (`pd.get_dummies`).
    *   As colunas resultantes do One-Hot Encoding com tipo 'bool' foram convertidas para 'int'.
    *   Outliers foram visualizados usando boxplots para as colunas num√©ricas. A detec√ß√£o de outliers foi realizada utilizando o m√©todo do Intervalo Interquartil (IQR), mas n√£o houve tratamento expl√≠cito no c√≥digo.

4.  **Balanceamento das Classes:** Para lidar com o desbalanceamento da vari√°vel alvo, diferentes t√©cnicas de balanceamento foram aplicadas no conjunto de treino.
    *   Os dados foram divididos em conjuntos de treino e teste, mantendo a propor√ß√£o da classe alvo (estratifica√ß√£o).
    *   As estrat√©gias de balanceamento testadas foram: Original (sem balanceamento), SMOTE (oversampling), RandomUnderSampler (undersampling) e SMOTEENN (combina√ß√£o de over e undersampling).
    *   As propor√ß√µes das classes ap√≥s a aplica√ß√£o de cada estrat√©gia foram visualizadas.

5.  **Modelagem Preditiva:** Foram treinados dois modelos de classifica√ß√£o: Regress√£o Log√≠stica e Random Forest.
    *   Um pipeline de pr√©-processamento foi definido utilizando `ColumnTransformer` para aplicar `StandardScaler` √†s colunas num√©ricas. As colunas categ√≥ricas (j√° em formato dummy) foram mantidas.
    *   Pipelines completos foram criados combinando o pr√©-processador e cada modelo.
    *   O desempenho de cada modelo com cada estrat√©gia de balanceamento foi avaliado usando valida√ß√£o cruzada (cv=5) no conjunto de treino balanceado, utilizando o F1-score como m√©trica.

6.  **Avalia√ß√£o de Modelos:** O modelo Random Forest treinado com SMOTE foi escolhido como exemplo para uma avalia√ß√£o mais detalhada no conjunto de teste n√£o balanceado.
    *   O modelo final foi treinado no conjunto de treino balanceado com SMOTE.
    *   As previs√µes e probabilidades de churn foram geradas para o conjunto de teste.
    *   Um relat√≥rio de classifica√ß√£o (`classification_report`) foi impresso, fornecendo m√©tricas como precis√£o, recall e F1-score para cada classe.
    *   A matriz de confus√£o foi visualizada usando um heatmap.
    *   A curva ROC (Receiver Operating Characteristic) e o valor AUC (Area Under the Curve) foram calculados e plotados para avaliar a capacidade do modelo de distinguir entre as classes.
    *   A curva Precision-Recall foi plotada para avaliar o trade-off entre precis√£o e recall em diferentes thresholds.
    *   O desempenho do modelo foi avaliado com diferentes thresholds de classifica√ß√£o para analisar o impacto na precis√£o e recall.

7.  **Interpreta√ß√£o e Explicabilidade:** M√©todos para entender a import√¢ncia das features foram aplicados.
    *   A import√¢ncia das features para o modelo Random Forest foi extra√≠da e visualizada usando um barplot.
    *   Os coeficientes das features para o modelo de Regress√£o Log√≠stica (treinado com SMOTE) foram extra√≠dos e visualizados para entender a dire√ß√£o e magnitude do impacto de cada feature.
    *   SHAP (SHapley Additive exPlanations) foi utilizado para fornecer interpretabilidade local e global do modelo Random Forest, visualizando o impacto de cada feature nas previs√µes individuais e no modelo como um todo atrav√©s de um summary plot.

# Resumo das principais descobertas

## Principais Fatores de Evas√£o

Os fatores mais influentes na evas√£o de clientes incluem:

- Tempo de Contrato (Tenure): Clientes com menor tempo de contrato apresentam maior propens√£o √† evas√£o.
- Encargos Mensais (Charges.monthly) e Encargos Totais (Charges.total): Valores mais altos est√£o associados a uma maior probabilidade de churn.
- Tipo de Contrato: Clientes com contratos de dois anos ou um ano demonstram menor probabilidade de evas√£o em compara√ß√£o com aqueles em contratos mensais.
- Servi√ßo de Internet (Fiber Optic): A presen√ßa deste servi√ßo foi identificada como um fator que aumenta a probabilidade de churn.
- Servi√ßos de Seguran√ßa e Suporte (TechSupport, OnlineSecurity, OnlineBackup): A ades√£o a esses servi√ßos est√° associada a uma menor probabilidade de evas√£o.
- M√©todo de Pagamento (Electronic check e Mailed check): Cheque Eletr√¥nico demonstrou aumentar a probabilidade de churn, enquanto Cheque Enviado parece estar associado a uma menor probabilidade.
- Contas Di√°rias (contas_diarias): A frequ√™ncia e o valor dos encargos impactam a decis√£o de evas√£o.

# Resumo do desempenho dos modelos

## Desempenho dos Modelos

Foram avaliados modelos de Regress√£o Log√≠stica e Random Forest com diferentes estrat√©gias de balanceamento. A tabela abaixo resume o desempenho no conjunto de teste, focando no F1-score para a classe de churn (evas√£o) e na m√©trica AUC.

| Estrat√©gia de Balanceamento | Modelo              | F1 Test (Churn) | AUC Test |
|-----------------------------|---------------------|-----------------|----------|
| Original                    | Logistic Regression | 0.621           | 0.843    |
| Original                    | Random Forest       | 0.555           | 0.812    |
| SMOTE                       | Logistic Regression | 0.550           | 0.831    |
| SMOTE                       | Random Forest       | 0.555           | 0.812    |
| RandomUnderSampler          | Logistic Regression | 0.619           | 0.843    |
| RandomUnderSampler          | Random Forest       | 0.604           | 0.814    |
| SMOTEENN                    | Logistic Regression | 0.603           | 0.836    |
| SMOTEENN                    | Random Forest       | 0.621           | 0.833    |

*Nota: O F1 Test (Churn) e o AUC Test foram calculados no conjunto de teste n√£o balanceado.*

Os resultados indicam que as estrat√©gias de balanceamento melhoraram o desempenho na valida√ß√£o cruzada no treino. Ao avaliar no conjunto de teste, o F1-score para a classe de churn variou, com a Regress√£o Log√≠stica (Original e RandomUnderSampler) e o Random Forest (SMOTEENN) apresentando os melhores resultados para esta m√©trica. O AUC foi relativamente consistente entre as estrat√©gias de balanceamento para cada modelo.

# Esbo√ßo da Estrutura do Projeto

## Estrutura do Projeto

O reposit√≥rio cont√©m os seguintes arquivos principais:

-   `telecomX_dados_tratados.ipynb`: O notebook Jupyter que documenta todo o processo de an√°lise, pr√©-processamento, modelagem e avalia√ß√£o.
-   `telecomX_dados_tratados.csv`: O conjunto de dados utilizado para a an√°lise e treinamento dos modelos.
-   `previsoes_churn.csv`: Arquivo CSV contendo as previs√µes de churn (real, predito e probabilidade) para o conjunto de teste.
-   `modelo_random_forest.pkl`: Arquivo pickle contendo o modelo final de Random Forest treinado, pronto para ser carregado e utilizado para novas previs√µes.
